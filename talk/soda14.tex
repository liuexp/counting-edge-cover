\documentclass[mathserif]{beamer}
\usepackage{indentfirst}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{fancybox}
\usepackage{fancyvrb}
%\usepackage{minted}
\usepackage{color}
\usepackage{makeidx}
%\usepackage{xeCJK}
%\usepackage{fontspec}
%\usepackage{lmodern}
\usepackage{subcaption}
%\setCJKmainfont[BoldFont={Adobe Heiti Std}, ItalicFont={AR PL New Kai}]{Adobe Song Std}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{array}
\usepackage{gnuplot-lua-tikz}
\usepackage{cite}
\usepackage{url}
\usepackage{hyperref}
\hypersetup{colorlinks=true,linkcolor=blue,anchorcolor=green,citecolor=blue}
\usepackage{wrapfig}
%\usepackage{lettrine}
%\usepackage{abstract}

% THEOREMS -------------------------------------------------------
%\newtheorem{Thm}{Theorem}
%\newtheorem{Cor}[Thm]{Corollary}
%\newtheorem{Conj}[Thm]{Conjecture}
%\newtheorem{Lem}[Thm]{Lemma}
%\newtheorem{Prop}[Thm]{Proposition}
\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem{Prob}{Problem}
%\newtheorem{Exam}{Example}
%\newtheorem{Def}[Thm]{Definition}
%\newtheorem{Rem}[theorem]{Remark}
\newtheorem{remark}[theorem]{Remark}
%\newtheorem{Not}[Thm]{Notation}
%\newtheorem*{Sol}{Solution}

% MATH -----------------------------------------------------------
\newcommand{\norm}[1]{\left\Vert#1\right\Vert}
\newcommand{\abs}[1]{\left\vert#1\right\vert}
\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\Real}{\mathbb R}
\newcommand{\eps}{\varepsilon}
\newcommand{\To}{\longrightarrow}
\newcommand{\BX}{\mathbf{B}(X)}
\newcommand{\A}{\mathcal{A}}
\newcommand{\CommentS}[1]{}
% CODE ----------------------------------------------------------
\newcommand{\PltImg}[1]{
\begin{center}
\input{#1}
\end{center}
}

\newenvironment{code}%
{\vglue 5pt \VerbatimEnvironment\begin{Sbox}\begin{minipage}{0.9\textwidth}\begin{small}\begin{Verbatim}}%
{\end{Verbatim}\end{small}\end{minipage}\end{Sbox}\setlength{\shadowsize}{2pt}\shadowbox{\TheSbox}\vglue 5pt}


\usepackage{pgf}
%\usepackage{tikz}
%\usetikzlibrary{arrows,automata}
%\usepackage[latin1]{inputenc}
\usepackage{verbatim}
\usepackage{listings}
%\usepackage{algorithmic} %old version; we can use algorithmicx instead
\usepackage{algorithm}
\usepackage[noend]{algpseudocode} %for pseudo code, include algorithmicsx automatically

\lstloadlanguages{C++, Lisp, Haskell, Python, Mathematica, Java,bash,Gnuplot,make,Matlab,PHP,Prolog,R,Ruby,sh,SQL,TeX,XML}


\title[\scshape Counting Edge Covers]{\scshape A Simple FPTAS for Counting Edge Covers}
\author[Jingcheng Liu]{Chengyu Lin\inst{1} \and Jingcheng Liu\inst{1} \and Pinyan Lu\inst{2}}
\institute[SJTU]{\scshape \inst{1} Shanghai Jiao Tong University \and \inst{2} Microsoft Research Asia}
\date[SODA 2014]{\scshape ACM-SIAM Symposium on Discrete Algorithms, 2014}
%\usetheme{Warsaw}
\usetheme{Madrid}
%\usetheme[numbers,totalnumber,compress,sidebarshades]{PaloAlto}
%\usetheme{Copenhagen}
%\usecolortheme{whale}
\usecolortheme{seahorse}
%\setbeamercolor{background canvas}{bg=blue!9}
%\setbeamertemplate{theorems}[ams style]
\setbeamertemplate{navigation symbols}{}
\setbeamercovered{transparent}

\begin{document}

\begin{frame}
	\titlepage
\end{frame}

\begin{frame}
	\frametitle{Overview}
	\tableofcontents
\end{frame}

\section{\scshape Introduction}

\begin{frame}
	\frametitle{Edge cover}
	\begin{definition}
		For an undirected input graph $G=(V,E)$, an {\bf edge cover} of $G$ is a set of edges $C$ covering all vertices.
	\end{definition}
	\begin{example}
		\begin{figure}[htbp]
			\centering
			\input{fig-edge-cover3.tex}
			\caption{An edge cover for Petersen graph\visible<2->{, with edges chosen being highlighted in red. Note that this is also a perfect matching.}}
		\end{figure}
	\end{example}

\end{frame}

\begin{frame}
	\frametitle{Edge cover}
	Edge cover is related to many other problems such as:
	\begin{itemize}
		\item Matching problem.
		\item Rtw-Mon-CNF. (read twice monotone CNF)
		\item Holant problem.
		\item \dots.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Relation to Matching}
	The minimal edge cover could be found via a greedy algorithm based on a maximum matching.
	\begin{example}
		Find edge covers by maximal matching?
		\begin{figure}[htp]
			\begin{subfigure}[b]{0.49\textwidth}
				\centering
				\input{fig-edge-cover1.tex}
				\caption{$G$ has a perfect matching.}
			\end{subfigure}
			\hfill
			\begin{subfigure}[b]{0.49\textwidth}
				\centering
				\input{fig-edge-cover2.tex}

				\caption{$G$ doesn't have a perfect matching.}
			\end{subfigure}
		\end{figure}
	\end{example}
	\pause
	\begin{remark}
		For a graph with a perfect matching, enumerating (sampling) perfect matchings is equivalent to enumerating (sampling) minimum edge covers.
	\end{remark}
\end{frame}

\begin{frame}
	\frametitle{ Relation to Rtw-Mon-CNF}
	Consider the following graph, its edge covers are exactly satisfying assignments to the following CNF formula, if we treat edges as variables, and vertices as clauses.
	\[
		\phi = (e_1 \vee e_2 \vee e_3) \wedge (e_1 \vee e_4) \wedge (e_4 \vee e_5 \vee e_2 ) \wedge (e_3 \vee e_5).
	\]

	\begin{figure}[htp]
		\centering
		\input{fig-cnf.tex}
		\caption{Graph representation for $\phi$.}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Counting Problems}
	A list of problems in their search, optimization, and counting versions.
	\bigskip

	\begin{minipage}[tb]{0.3\linewidth}
		{\bf Search problems:}
		\begin{itemize}
			\item SAT.
				\pause
			\item Find a (perfect) matching.
				\pause
			\item Find an edge cover.
			\item \dots.
		\end{itemize}
	\end{minipage}
	\pause
	\begin{minipage}[tb]{0.3\linewidth}
		{\bf Optimizations:}
		\begin{itemize}
			\item MAX-SAT.
				\pause
			\item Find a maximum matching.
				\pause
			\item Find a minimum edge cover.
			\item \dots.
		\end{itemize}
	\end{minipage}
	\pause
	\begin{minipage}[tb]{0.3\linewidth}
		{\bf Counting problems:}
		\begin{itemize}
			\item \#SAT.
				\pause
			\item Counting matchings.
				\pause
			\item Counting edge covers.
			\item \dots.
		\end{itemize}
	\end{minipage}
\end{frame}

\begin{frame}
	\frametitle{Why counting?}
Besides theoretical computer science, counting problems are also related to many problems from other discipline such as:
\begin{itemize}
	\item Partition function of Statistical physics. 
		\pause
	\item Graph polynomials. 
		\pause
	\item Sampling, learning and inference. 
		\pause
	\item Query evaluations of probabilistic database.
	\item \dots.
\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Approximate Counting}
	Many interesting problems in the exact counting regimes, including counting edge cover, is hard (\#P-complete).
	Instead we look for these two types of polynomial time approximation scheme:
	\pause
	\begin{definition}[FPTAS]
		For given parameter $\eps > 0$ and an instance of a particular problem class, if the algorithm outputs a number $\hat{N}$ such that $(1-\eps) N \leq \hat{N} \leq (1+\eps) N$, where $N$ is the accurate answer of the problem instance, and the running time is bounded by $poly(n, 1/ \eps)$ with $n$ being the size of instance, this is called the {\bf FPTAS (fully polynomial time approximation scheme)}.

	\end{definition}
	\pause
	\begin{definition}[FPRAS]
		A randomized relaxation of FPTAS is known as {\bf FPRAS (fully polynomial time randomized approximation scheme)}, which uses random bits and only outputs $\hat{N}$ to the desired precision with high probability.
	\end{definition}
\end{frame}

%\begin{frame}
%	\frametitle{MCMC vs. correlation decay}
%	
%\end{frame}


\section{\scshape Our Result}

\begin{frame}
	\frametitle{Main Result}
	Previous work:
	\begin{itemize}
		\item Only an MCMC-based FPRAS is known for counting edge covers in graphs with maximum degree $3$.
		\item The correlation decay based FPTAS for anti-ferromagnetic 2-spins systems (e.g. counting independent sets) goes beyond the best known MCMC based FPRAS and achieves the boundary of approximability.
	\end{itemize}

	\pause
	Our main result is a correlation based FPTAS for counting edge covers for general graphs, which provides another example where the tractable range for correlation decay based FPTAS exceeds the sampling based FPRAS.
\end{frame}

\begin{frame}
	\frametitle{Dangling instance} % Here we introduce the only concept that you need to keep in mind.

\begin{definition}
	A {\bf dangling edge} $e=(u,\_)$ of a graph is such singleton edge with exactly one end-point vertex $u$, as shown in the Figure \ref{fig:G}.
\end{definition}
\input{fig-dangling.tex}
\end{frame}

\begin{frame}
	\frametitle{Counting v.s. Marginal Probability}
	Recall our counting problem:
	\begin{block}{Problem}
	Let $EC(G)$ be the set of edge covers.

	Goal: estimate $\abs{EC(G)}$.
	\end{block}
	
	\pause
	Let $X$ be an edge cover sampled uniformly from $EC(G)$, consider the following marginal probability:

	for an edge $e$, we write $P(G,e) \triangleq \Pr ( e \notin X)$.

	\bigskip

	Solution: estimate $P(G,e)$.
\end{frame}

\begin{frame}
	\frametitle{Counting from marginal probability}
	Recall that the set of all edges $E$ is an edge cover.
	For a randomly sampled edge cover $X$, what is $\Pr (X=E)$?
	\pause
	\begin{align*}
		\uncover<+->{\Pr (X=E) &= \frac{1}{\abs{EC(G)}} \\}
		\visible<+->{\Pr (X=E) &= \Pr ( \forall i, e_i \in X) \\}
		\visible<+->{&= \Pr (e_1 \in X) \Pr(e_2 \in X \mid e_1 \in X) \cdots\\ }
		\visible<+->{&= \prod_i \Pr( e_i \in X \mid \set{e_j}_{j=1}^{i-1} \subseteq X) \\}
		\visible<+->{&= \prod_i \left(1-P(G_i,e_i)\right), }
	\end{align*}
	\visible<.->{where $G_1 = G, G_{i+1} = G_i - e_i - u_i - v_i$.}

	\pause
	Therefore,
	\[\frac{1}{\abs{EC(G)}} = \prod_i \left(1-P(G_i,e_i)\right). \]
	
\end{frame}

% maybe add figures of normal edge examples here

\begin{frame}
	\frametitle{Estimating Marginal Probability}
	We focus on $e$ is dangling.
	\[
		P(G, e) = \frac{1-\prod_{i=1}^d P(G_i, e_i)}{2 - \prod_{i=1}^d P(G_i, e_i)}, %= \frac{1}{2} - \frac{0.5 \prod_{i=1}^d P(G_i, e_i)}{2 - \prod_{i=1}^d P(G_i, e_i)}
	\]
	where $G_1 \triangleq G - e - u$, and $G_{i+1} \triangleq G_{i} - e_{i}$.

	\pause
	Truncate with a modified recursion depth:
	\[
		P(G, e, L) = 
		\begin{cases}
			\frac{1}{2}, & \hbox{ if $L \leq 0$;} \\
			\frac{1-\prod_{i=1}^d P(G_i, e_i, L - \lceil \log_6{(d+1)} \rceil)}{2 - \prod_{i=1}^d P(G_i, e_i, L - \lceil \log_6{(d+1)} \rceil)}, &\hbox{otherwise.}
		\end{cases}
	\]

\end{frame}

\begin{frame}
	\frametitle{Correlation Decay}

\begin{proposition}
	Given graph $G$, edge $e$ and depth $L$,
	\[\abs{P(G,e,L) - P(G,e)} \leq 3\cdot(\frac{1}{2})^{L+1}\]
\end{proposition}
\end{frame}

\begin{frame}
	\begin{center}
		\Huge \scshape Thank you!
	\end{center}
\end{frame}
\end{document}
