\section{The Computation Tree Recursion}
In this section, we provide a recursion for computing the marginal probability $P(G, e)$ with that of smaller instances.

\subsection{$e$ is free}
%This case is trivial.
\begin{Prop}
	\[P(G,e) = \frac{1}{2}\]
\end{Prop}
\begin{proof}
	If $e$ is a free edge, then any edge cover with $e$ chosen is in one-to-one correspondence to an edge cover with $e$ not chosen. Hence exactly half of the edge covers in $EC(G)$ does not choose $e$, so $P(G, e) = \frac{1}{2}$.
\end{proof}

\subsection{$e$ is dangling}
\begin{Lem}
For graph $G=(V,E)$ with a dangling edge $e=(u,\_)$, denote the $d$
edges incident with $u$ except $e$ as $e_1, e_2, \ldots, e_d$,
let $G_i \triangleq G - e - u - \sum_{k=1}^{i-1} e_k$ (specifically, $G_1 \triangleq G - e - u$),
	\begin{equation}
		P(G, e) = \frac{1-\prod_{i=1}^d P(G_i, e_i)}{2 - \prod_{i=1}^d P(G_i, e_i)} %= \frac{1}{2} - \frac{0.5 \prod_{i=1}^d P(G_i, e_i)}{2 - \prod_{i=1}^d P(G_i, e_i)}
		\label{propp3rg}
	\end{equation}
\end{Lem}
\begin{proof}
	For $\boldsymbol\alpha \in \set{0,1}^d$, let $EC_{\boldsymbol\alpha}(G-e-u)$ be the set of edge coverings in $G-e-u$ such that its restriction onto $\set{e_i}_{i=1}^{d}$ is consistent with $\boldsymbol\alpha$, denote $Z_{\boldsymbol\alpha} = \norm{EC_{\boldsymbol\alpha}(G-e-u)}$, and $Z = \sum_{\boldsymbol\alpha \in \set{0,1}^d} Z_{\boldsymbol\alpha} = \norm{EC(G-e-u)}$. % \triangleq \set{X : X\subseteq E, $

		Also note that as long as $\boldsymbol\alpha \neq 0$, counting edge coverings with restriction $\boldsymbol\alpha$ is the same in either $G$, $G-e$, or $G-e-u$, so it's enough to work with $G-e-u$. Note that in $G-e-u$, for every $i$, $e_i$ is either dangling or free, but not normal.
	\begin{align*}
		P(G,e) = & \frac{\norm{EC(G-e)}}{\norm{EC(G)}}
		= \frac{\sum_{\boldsymbol\alpha \in \set{0,1}^d, \boldsymbol\alpha \neq \mathbf{0}} Z_{\boldsymbol\alpha} }{ Z_{\mathbf{0}} + 2 \sum_{\boldsymbol\alpha \in \set{0,1}^d, \boldsymbol\alpha \neq \mathbf{0}} Z_{\boldsymbol\alpha}}
		=\frac{Z - Z_0}{2 Z - Z_0}
		= \frac{1 - \frac{Z_{\mathbf{0}}}{Z}}{ 2 - \frac{Z_{\mathbf{0}}}{Z}}.
	\end{align*}

	Now consider the term $\frac{Z_{\mathbf{0}}}{Z}$, it says the probability that a uniformly random edge cover drawn from $EC(G-e-u)$ picked none of $\set{e_i}_{i=1}^{d}$, so
	\begin{align*}
		\frac{Z_{\mathbf{0}}}{Z}=\mathbb{P} \left( \set{e_i} = \mathbf{0}\right) = \mathbb{P} (e_1 = 0) \prod_{i=2}^d \mathbb{P} \left(e_i = 0 \mid \set{e_j}_{j=1}^{i-1} = \mathbf{0}\right) = \prod_{i=1}^d P(G_i, e_i).
	\end{align*}

	Hence concludes the proof.
	
\end{proof}


\subsection{$e$ is a normal edge}
By definition we have
\begin{equation}
	P(G,e) = \frac{\norm{EC(G-e)}}{\norm{EC(G-e)} + \norm{EC(G-e-u-v)} }.
\end{equation}


	For $e=(u,v)$ as a normal edge, let $\set{e_i}$ be the set of edges incident with vertex $u$ except $e$, and $\set{f_i}$ be the set of edges incident with vertex $v$ except $e$, and $d_1 = \norm{\set{e_i}}, d_2 = \norm{\set{f_i}}$, now for $\boldsymbol\alpha \in \set{0,1}^{d_1}, \boldsymbol\beta \in \set{0,1}^{d_2}$, we use $E_{\boldsymbol\alpha,\boldsymbol\beta}^G$ to denote the set of edge covers for $G$ such that its restriction to $\set{e_i}_{i=1}^{d_1}$ is consistent with $\boldsymbol\alpha$, and restriction to $\set{f_i}_{i=1}^{d_2}$ is consistent with $\boldsymbol\beta$.

	Denote $Z_{\boldsymbol\alpha, \boldsymbol\beta}^G \triangleq \norm{EC_{\boldsymbol\alpha, \boldsymbol\beta}(G)}$, $G_1 \triangleq G-e, G_2 \triangleq G-e-u-v$. As an illustration, given a normal edge $e=(u,v)$ in $G$ as in Figure \ref{fig:generalG}, $G_1$ and $G_2$ is like Figure \ref{fig:generalG-e} and Figure \ref{fig:generalG-e-u-v}.

\begin{figure}[htp]
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\setlength{\unitlength}{1mm}
		\begin{picture}(20,30)
			\put(0,0){\circle*{10}}
			\put(0,0){\line(1,1){10}}
			\put(20,0){\circle*{10}}
			\put(20,0){\line(-1,1){10}}
			\put(10,10){\circle*{10}}
			\put(10,10){\line(0,1){10}}
			\put(10,20){\circle*{10}}
			\put(10,20){\line(1,1){10}}
			\put(10,20){\line(-1,1){10}}
			\put(20,30){\circle*{10}}
			\put(0,30){\circle*{10}}
			\put(14,20){$v$}
			\put(14,10){$u$}
			\put(8,14.5){$e$}
			\put(2,6){$e_1$}
			\put(15,5){$e_2$}
			\put(3,28){$f_1$}
			\put(13,28){$f_2$}
		\end{picture}
		\caption{$G$}
		\label{fig:generalG}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\setlength{\unitlength}{1mm}
		\begin{picture}(20,30)
			\put(0,1){\circle*{10}}
			\put(0,0){\line(1,1){10}}
			\put(20,1){\circle*{10}}
			\put(20,0){\line(-1,1){10}}
			\put(10,10){\circle*{10}}
			\put(10,20){\circle*{10}}
			\put(10,20){\line(1,1){10}}
			\put(10,20){\line(-1,1){10}}
			\put(20,30){\circle*{10}}
			\put(0,30){\circle*{10}}
			\put(14,20){$v$}
			\put(14,10){$u$}
			\put(2,6){$e_1$}
			\put(15,5){$e_2$}
			\put(3,28){$f_1$}
			\put(13,28){$f_2$}
		\end{picture}
		\caption{$G_1 = G-e$}
		\label{fig:generalG-e}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\setlength{\unitlength}{1mm}
		\begin{picture}(20,20)
			\put(0,1){\circle*{10}}
			\put(0,1){\line(0,1){10}}
			\put(20,1){\circle*{10}}
			\put(20,1){\line(0,1){10}}
			\put(20,30){\circle*{10}}
			\put(20,30){\line(0,-1){10}}
			\put(0,30){\circle*{10}}
			\put(0,30){\line(0,-1){10}}
			\put(2,6){$e_1$}
			\put(15,6){$e_2$}
			\put(2,24){$f_1$}
			\put(15,24){$f_2$}
		\end{picture}
		\caption{$G_2 = G-e-u-v$}
		\label{fig:generalG-e-u-v}
	\end{subfigure}
	\caption{Normal edge examples.}
\end{figure}

	Note that as long as $\boldsymbol\alpha \neq \mathbf{0} , \boldsymbol\beta \neq \mathbf{0}$, working with $G_1$ and working with $G_2$ is the same with restriction to $\boldsymbol\alpha$ and $\boldsymbol\beta$, or formally,
\[\norm{EC(G-e)} = \sum_{\boldsymbol\alpha \neq \mathbf{0}, \boldsymbol\beta \neq \mathbf{0}} Z_{\boldsymbol\alpha, \boldsymbol\beta}^{G_1} = \sum_{\boldsymbol\alpha \neq \mathbf{0}, \boldsymbol\beta \neq \mathbf{0}} Z_{\boldsymbol\alpha, \boldsymbol\beta}^{G_2}\]
%\[C_2 = \sum_{\boldsymbol\alpha , \boldsymbol\beta} Z_{\boldsymbol\alpha, \boldsymbol\beta}^{G_2}\]

Since only $G_2$ is involved, denote $Z_{\boldsymbol\alpha, \boldsymbol\beta} \triangleq Z_{\boldsymbol\alpha, \boldsymbol\beta}^{G_2}, Z \triangleq \sum_{\boldsymbol\alpha \in \set{0,1}^{d_1} , \boldsymbol\beta \in \set{0,1}^{d_2}} Z_{\boldsymbol\alpha, \boldsymbol\beta}$,
and
$G_i^1 \triangleq G_2 - \sum_{k=1}^{i-1} e_k$,
$G_i^2 \triangleq G_2 - \sum_{k=1}^{d_1}e_k - \sum_{k=1}^{i-1} f_k$,
$G_i^3 \triangleq G_2 - \sum_{k=1}^{i-1} f_k$,


\begin{Lem}
	
	\[P(G,e) =  1 - \frac{1}{2 + \prod_{i=1}^{d_1} P(G_i^1, e_i) \cdot \prod_{i=1}^{d_2} P(G_i^2, f_i) - \prod_{i=1}^{d_1} P(G_i^1, e_i) - \prod_{i=1}^{d_2} P(G_i^3, f_i)}\]

\end{Lem}
\begin{proof}

	\begin{align*}
P(G,e) &= \frac{\sum_{\boldsymbol\alpha \neq \mathbf{0}, \boldsymbol\beta \neq \mathbf{0}} Z_{\boldsymbol\alpha, \boldsymbol\beta}}{Z + \sum_{\boldsymbol\alpha \neq \mathbf{0}, \boldsymbol\beta \neq \mathbf{0}} Z_{\boldsymbol\alpha, \boldsymbol\beta}} \\
&=\frac{Z - \sum_{\boldsymbol\alpha}Z_{\boldsymbol\alpha,\mathbf{0}} - \sum_{\boldsymbol\beta} Z_{\mathbf{0}, \boldsymbol\beta} + Z_{\mathbf{0}, \mathbf{0}}}{2Z - \sum_{\boldsymbol\alpha}Z_{\boldsymbol\alpha,\mathbf{0}} - \sum_{\boldsymbol\beta} Z_{\mathbf{0}, \boldsymbol\beta} + Z_{\mathbf{0}, \mathbf{0}}} \\
&= 1 - \frac{1}{2 + \mathbb{P}\left( \boldsymbol\alpha = \mathbf{0}, \boldsymbol\beta = \mathbf{0} \right) - \mathbb{P} \left( \boldsymbol\alpha = \mathbf{0} \right) - \mathbb{P} \left( \boldsymbol\beta = \mathbf{0} \right)}
	\end{align*}

	where $\mathbb{P} \left( \boldsymbol\alpha = \mathbf{0}, \boldsymbol\beta = \mathbf{0} \right) \triangleq \frac{Z_{\mathbf{0},\mathbf{0}}}{Z}, \mathbb{P} \left( \boldsymbol\alpha = \mathbf{0} \right) \triangleq \frac{\sum_{\boldsymbol\beta} Z_{\mathbf{0}, \boldsymbol\beta} }{Z}, \mathbb{P} \left( \boldsymbol\beta = \mathbf{0} \right) \triangleq \frac{\sum_{\boldsymbol\alpha} Z_{ \boldsymbol\alpha , \mathbf{0}} }{Z}$.

Now consider the three terms respectively,
	\begin{align*}
		\mathbb{P}\left( \boldsymbol\alpha = \mathbf{0}\right) &= \mathbb{P} \left( \set{e_i} = \mathbf{0}\right) =	\prod_{i=1}^{d_1} P(G_i^1, e_i) \\
		\mathbb{P}\left( \boldsymbol\beta = \mathbf{0}\right) &= \mathbb{P} \left( \set{f_i} = \mathbf{0}\right) =	\prod_{i=1}^{d_2} P(G_i^3, f_i) \\
		\mathbb{P}\left( \boldsymbol\alpha = \mathbf{0}, \boldsymbol\beta = \mathbf{0} \right) &=  \mathbb{P} \left( \boldsymbol\alpha = \mathbf{0} \right) \cdot \mathbb{P}\left( \boldsymbol\beta = \mathbf{0} \mid \boldsymbol\alpha = \mathbf{0} \right) \\
		&=  \mathbb{P} \left( \set{e_i} = \mathbf{0}\right) \cdot \mathbb{P} \left( \set{f_i} = \mathbf{0} \mid \set{e_i} = \mathbf{0} \right) \\
		&= \prod_{i=1}^{d_1} \mathbb{P} \left( e_i = 0 \mid \set{e_j}_{j=1}^{i-1} = \mathbf{0} \right) \cdot \prod_{i=1}^{d_2} \mathbb{P} \left( f_i = 0 \mid \set{e_j}_{j=1}^{d_1} = \mathbf{0},\set{f_j}_{j=1}^{i-1} = \mathbf{0} \right) \\
		&= \prod_{i=1}^{d_1} P(G_i^1, e_i) \cdot \prod_{i=1}^{d_2} P(G_i^2, f_i)
	\end{align*}

	Hence concludes the proof.
\end{proof}

Note that for every $i$, $e_i$ is dangling or free in $G_i^1$, $f_i$ is dangling or free in $G_i^3$, and in $G_i^2$, neither $e_i$ nor $f_i$ is normal.

